{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qj2Uh-mU-dzf",
    "outputId": "57565865-8caa-4c5f-f5a7-1cba5333428d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opendatasets in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (0.1.22)\n",
      "Requirement already satisfied: tqdm in c:\\program files\\python38\\lib\\site-packages (from opendatasets) (4.67.1)\n",
      "Requirement already satisfied: click in c:\\program files\\python38\\lib\\site-packages (from opendatasets) (8.1.8)\n",
      "Requirement already satisfied: kaggle in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (from opendatasets) (1.7.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (from click->opendatasets) (0.4.6)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (from kaggle->opendatasets) (1.17.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (from kaggle->opendatasets) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
      "Requirement already satisfied: idna in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (from kaggle->opendatasets) (3.10)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (from kaggle->opendatasets) (2025.1.31)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (from kaggle->opendatasets) (8.0.4)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (from kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: bleach in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (from kaggle->opendatasets) (6.1.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (from kaggle->opendatasets) (4.25.7)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\program files\\python38\\lib\\site-packages (from kaggle->opendatasets) (56.0.0)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (from kaggle->opendatasets) (2.2.3)\n",
      "Requirement already satisfied: requests in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (from kaggle->opendatasets) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (from kaggle->opendatasets) (3.4.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# !pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9maHc_q9-_DX"
   },
   "outputs": [],
   "source": [
    "# import opendatasets as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foN5s9w__Gm8",
    "outputId": "858ecb15-c7d0-4c44-d96a-531bc0ca1d85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\sentiment140\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "# od.download(\"https://www.kaggle.com/datasets/kazanova/sentiment140\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Rq3RCG9o_K3Y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3cxMKjQ_nRK",
    "outputId": "6b4292dd-4ac7-4756-e574-9f166b84e283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (3.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\program files\\python38\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: click in c:\\program files\\python38\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\dubai computers\\appdata\\roaming\\python\\python38\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bks9HGAC_6VE",
    "outputId": "690fa4a9-aa60-49a4-e965-589f2cc00a2b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Dubai\n",
      "[nltk_data]     Computers\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gn2j_Ker_8B7",
    "outputId": "f9bfd42e-935f-43bb-b33d-2665baa6066b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kiHVNzoaAH8W"
   },
   "outputs": [],
   "source": [
    "twitter_data = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", encoding='latin1', on_bad_lines=\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gysw0wUwANKe",
    "outputId": "ab147b03-21b6-425b-8a92-2b894287b19a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599999, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZGNFuPGHC1PL"
   },
   "outputs": [],
   "source": [
    "# Define the custom column names to assign to each column in the dataset\n",
    "# The original CSV has no header, so we provide our own\n",
    "column_names = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "\n",
    "# Load the Sentiment140 CSV dataset using pandas\n",
    "twitter_data = pd.read_csv(\n",
    "    \"training.1600000.processed.noemoticon.csv\",  # Path to the CSV file (1.6 million tweets)\n",
    "    names=column_names,  # Assign the custom column names we defined above (since original file has no header row)\n",
    "    encoding='latin1',  # Encoding used to properly read special characters in tweets (like emojis or symbols)\n",
    "    engine='c',  # Use the C parser (default and faster), handles large files more efficiently than 'python' engine\n",
    "    on_bad_lines=\"skip\"  # If a row is malformed (e.g., missing or extra columns), skip that row instead of throwing an error\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g10BDFRLAaip",
    "outputId": "d5051eb8-2362-4f44-b6b2-dfbb768c9f06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "VlZSH0ArCsxE",
    "outputId": "4fd588b0-dcd1-4e20-ab5b-0d5240448d67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "aekbh4kRD8IW",
    "outputId": "397b3914-3691-4288-9fb8-526d3d4f6d9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "ids       0\n",
       "date      0\n",
       "flag      0\n",
       "user      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "jBw-GJEdEA0-",
    "outputId": "03d8b1cf-bd23-4453-c452-b780d5b3ba79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    800000\n",
       "4    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzk0H3sHg6V2"
   },
   "source": [
    "convert 4 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gzcBpGIpEG9r"
   },
   "outputs": [],
   "source": [
    "twitter_data.replace({\"target\": {4:1}}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNRbHYHvhDCF"
   },
   "source": [
    "0 --> Negative\n",
    "1 --> Positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7kVa5EQhS-_"
   },
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zwPKV_1hZ4u"
   },
   "source": [
    "Stemming is process of reducing of a word to its Root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ab8vkJD3g4Lx"
   },
   "outputs": [],
   "source": [
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Lc3By0CXIEU-"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "def stemming(content):\n",
    "    stemmed_content = re.sub(\"[^a-zA-Z]\", \" \", content) ## ^ mean remove all things excepte character (a-zA-Z) # Remove everything except letters\n",
    "    stemmed_content = stemmed_content.lower()# Convert to lowercase\n",
    "    stemmed_content = stemmed_content.split()# Tokenize into words\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if word not in stop_words]\n",
    "\n",
    "    return \" \".join(stemmed_content)  # Join back to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "fbqcdy__g3_1"
   },
   "outputs": [],
   "source": [
    "twitter_data[\"stemmed_content\"] = twitter_data[\"text\"].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "lhZwXRkpg3vl",
    "outputId": "76751161-100c-48e3-eb50-0469a89c28a5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>stemmed_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>switchfoot http twitpic com zl awww bummer sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset updat facebook text might cri result sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>kenichan dive mani time ball manag save rest g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>nationwideclass behav mad see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \\\n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...   \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...   \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire    \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                     stemmed_content  \n",
       "0  switchfoot http twitpic com zl awww bummer sho...  \n",
       "1  upset updat facebook text might cri result sch...  \n",
       "2  kenichan dive mani time ball manag save rest g...  \n",
       "3                    whole bodi feel itchi like fire  \n",
       "4                      nationwideclass behav mad see  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDBx3iuYg3pA",
    "outputId": "fe56b321-e118-4c38-ed17-5717511b6eef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          switchfoot http twitpic com zl awww bummer sho...\n",
      "1          upset updat facebook text might cri result sch...\n",
      "2          kenichan dive mani time ball manag save rest g...\n",
      "3                            whole bodi feel itchi like fire\n",
      "4                              nationwideclass behav mad see\n",
      "                                 ...                        \n",
      "1599995                           woke school best feel ever\n",
      "1599996    thewdb com cool hear old walt interview http b...\n",
      "1599997                         readi mojo makeov ask detail\n",
      "1599998    happi th birthday boo alll time tupac amaru sh...\n",
      "1599999    happi charitytuesday thenspcc sparkschar speak...\n",
      "Name: stemmed_content, Length: 1600000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(twitter_data[\"stemmed_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lojbomv0g3jD",
    "outputId": "babe9219-960a-4ff4-bc09-b6e6177f9ecf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0\n",
      "1          0\n",
      "2          0\n",
      "3          0\n",
      "4          0\n",
      "          ..\n",
      "1599995    1\n",
      "1599996    1\n",
      "1599997    1\n",
      "1599998    1\n",
      "1599999    1\n",
      "Name: target, Length: 1600000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(twitter_data[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "an6oT7T4w7BT"
   },
   "source": [
    "# Separating Label and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "S5mL1Z6-g3cS"
   },
   "outputs": [],
   "source": [
    "x = twitter_data[\"stemmed_content\"].values\n",
    "y = twitter_data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "YcwOSRj9g2lf"
   },
   "outputs": [],
   "source": [
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "KUe9u68HEUyS"
   },
   "outputs": [],
   "source": [
    "# print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJ7QhizgxXHZ"
   },
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "RjliAz3_xUvl"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AuzGPMBCxnW5",
    "outputId": "57abcde1-253d-4b30-94d6-e8d3d2bd98cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000,) (1280000,) (320000,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Jv-1au8HyUNa"
   },
   "outputs": [],
   "source": [
    "# print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Jh6q1QZzyYRi"
   },
   "outputs": [],
   "source": [
    "# print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfR_QLStyckb"
   },
   "source": [
    "# converting Textual to Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "f41V-sfQyaGN"
   },
   "outputs": [],
   "source": [
    "# apply vectorizer to convert in vector matrix\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "cssBWPtrymaX"
   },
   "outputs": [],
   "source": [
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVZbxgxS1jor"
   },
   "source": [
    "\n",
    "Original Tweet\tTF-IDF Vector...\n",
    "\"i love ai\"\t[0.56, 0.78, 0.34, ..., 0],\n",
    "\"ai is amazing\"\t[0.12, 0.44, 0.89, ..., 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Vectorizer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "\n",
    "filename = \"vectorizer_jani_model.pkl\"\n",
    "# Save using Pickle\n",
    "with open(\"vectorizer_jani_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vectorizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import joblib\n",
    "# # Save using Joblib\n",
    "# joblib.dump(vectorizer, \"vectorizer_jani_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "FmvRR0Cz1Mj3"
   },
   "outputs": [],
   "source": [
    "# print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ySxXsNN6KXw"
   },
   "source": [
    "# Training MOdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "GRxmGhh81Mb8"
   },
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(max_iter=1000, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "eXPygc801MW1",
    "outputId": "b85b15b4-5fe0-41e8-a917-1c1ff8bfb0a1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktTGP-Qs1MRw",
    "outputId": "e19452d5-4c6e-40bc-c744-8b7a85d50bc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.8646875"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.score(x_test, y_test)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11Xev-0pKTH_"
   },
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "q911rMC-1L63"
   },
   "outputs": [],
   "source": [
    "x_train_pred = lr_model.predict(x_train)\n",
    "train_data_accuracy = accuracy_score(x_train_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v7klWD1z1Lzn",
    "outputId": "7e3334c4-9b09-402e-df78-272494029c89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Data :  0.81027734375\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score of Training Data : \", train_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "gqtwz_wf1Lsl"
   },
   "outputs": [],
   "source": [
    "x_test_pred = lr_model.predict(x_test)\n",
    "test_data_accuracy = accuracy_score(x_test_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VszQFpLWyz-m",
    "outputId": "cdc27ac2-4d0f-4aea-e594-f97356e89788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Data :  0.778646875\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score of Training Data : \", test_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save model\n",
    "with open('my_trained_pickle_model.pkl', 'wb') as file:\n",
    "    pickle.dump(lr_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vectorizer (optional but recommended)\n",
    "with open('vectorizer_pickle.pkl', 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joblib Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_Trained_joblib_model.joblib']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save model\n",
    "joblib.dump(lr_model, 'my_Trained_joblib_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer_joblib.joblib']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save vectorizer\n",
    "joblib.dump(vectorizer, 'vectorizer_joblib.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_trained_pickle_model.pkl', 'rb') as file:\n",
    "    loaded_model_pickle = pickle.load(file)\n",
    "\n",
    "with open('vectorizer_pickle.pkl', 'rb') as file:\n",
    "    loaded_vectorizer_pickle = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pred = loaded_model_pickle.predict(x_train)\n",
    "train_data_accuracy = accuracy_score(x_train_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81027734375"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Predictionsss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: I hate this app, it's terrible!\n",
      "Prediction: Negative\n",
      "\n",
      "Tweet: This is amazing, I love it!\n",
      "Prediction: Positive \n",
      "\n",
      "Tweet: Worst experience ever.\n",
      "Prediction: Negative\n",
      "\n",
      "Tweet: I'm so happy with the service.\n",
      "Prediction: Positive \n",
      "\n"
     ]
    }
   ],
   "source": [
    "custom_tweets = [\n",
    "    \"I hate this app, it's terrible!\",\n",
    "    \"This is amazing, I love it!\",\n",
    "    \"Worst experience ever.\",\n",
    "    \"I'm so happy with the service.\"\n",
    "]\n",
    "\n",
    "# Transform and predict\n",
    "transformed = loaded_vectorizer_pickle.transform(custom_tweets)\n",
    "predictions = loaded_model_pickle.predict(transformed)\n",
    "\n",
    "# Show results\n",
    "for tweet, pred in zip(custom_tweets, predictions):\n",
    "    sentiment = \"Positive \" if pred == 1 else \"Negative\"\n",
    "    print(f\"Tweet: {tweet}\\nPrediction: {sentiment}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8iuUcZd54ts9",
    "outputId": "5a398376-b361-4564-c1fd-81f3d74c4873"
   },
   "outputs": [],
   "source": [
    "# # Load the tweet\n",
    "# x_new = x_test[300]  # Raw tweet text\n",
    "\n",
    "# # Transform the tweet using the same vectorizer used in training\n",
    "# x_new_transformed = vectorizer.transform([x_new])  # Convert to feature vector\n",
    "\n",
    "# # Print original sentiment\n",
    "# print(\"Original Sentiment:\", y_test.iloc[300])\n",
    "\n",
    "# # Make prediction\n",
    "# prediction = loaded_model.predict(x_new_transformed)\n",
    "# print(\"Prediction:\", prediction)\n",
    "\n",
    "# if prediction[0] == 0:\n",
    "#     print(\"Negative Tweet\")\n",
    "# else:\n",
    "#     print(\"Positive Tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jGhdINct7c1y",
    "outputId": "f8d70cfd-2e0f-461f-b6d9-8c9a6b6fa104"
   },
   "outputs": [],
   "source": [
    "# x_new = x_test[3]\n",
    "# print(\"Actual Sentiment:\", y_test.iloc[3])\n",
    "\n",
    "# x_new_vector = vectorizer.transform([x_new])\n",
    "# prediction = loaded_model.predict(x_new_vector)\n",
    "# print(\"Prediction:\", prediction)\n",
    "\n",
    "# if (prediction[0] == 0):\n",
    "#   print(\"Negative Tweet\")\n",
    "# else:\n",
    "#   print(\"Positive Tweet\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
